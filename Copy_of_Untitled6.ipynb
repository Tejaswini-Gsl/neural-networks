{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1a5L3GGLy1_c1ybJOBB5RtVMIxoodyenP",
      "authorship_tag": "ABX9TyNVXI6XTQdmDY2OpohMgAVj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejaswini-Gsl/neural-networks/blob/main/Copy_of_Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SE7V6nJu0kQm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import os\n",
        "import librosa as lr\n",
        "import shutil\n",
        "import dask.array as da\n",
        "import h5py\n",
        "import glob\n",
        "# import resampy\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# from keras.models import Model, load_model\n",
        "# from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "# from keras.layers import Dropout, Input, BatchNormalization\n",
        "# from keras.optimizers import Nadam\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing english dataset\n",
        "\n",
        "other_df_en = pd.read_csv('/content/drive/MyDrive/neural dataset/en/other.tsv', sep='\\t')\n",
        "validate_sen_df_en = pd.read_csv('/content/drive/MyDrive/neural dataset/en/validated.tsv', sep='\\t')\n",
        "unvalidate_sen_df_en = pd.read_csv('/content/drive/MyDrive/neural dataset/en/invalidated.tsv', sep='\\t')\n",
        "other_df_de = pd.read_csv('/content/drive/MyDrive/neural dataset/de/other.tsv', sep='\\t')\n",
        "validate_sen_df_de = pd.read_csv('/content/drive/MyDrive/neural dataset/de/validated.tsv', sep='\\t')\n",
        "unvalidate_sen_df_de = pd.read_csv('/content/drive/MyDrive/neural dataset/de/invalidated.tsv', sep='\\t')\n",
        "other_df_ca = pd.read_csv('/content/drive/MyDrive/neural dataset/ca/other.tsv', sep='\\t')\n",
        "validate_sen_df_ca = pd.read_csv('/content/drive/MyDrive/neural dataset/ca/validated.tsv', sep='\\t')\n",
        "unvalidate_sen_df_ca = pd.read_csv('/content/drive/MyDrive/neural dataset/ca/invalidated.tsv', sep='\\t')\n",
        "\n",
        "print(validate_sen_df_en.shape,validate_sen_df_ca.shape,validate_sen_df_de.shape)\n",
        "print(\"values of en:\",other_df_en['sentence_domain'].notnull().sum(),validate_sen_df_en['sentence_domain'].notnull().sum(),unvalidate_sen_df_en['sentence_domain'].notnull().sum())\n",
        "print(\"values of de:\",other_df_de['sentence_domain'].notnull().sum(),validate_sen_df_de['sentence_domain'].notnull().sum(),unvalidate_sen_df_de['sentence_domain'].notnull().sum())\n",
        "print(\"values of ca:\",other_df_ca['sentence_domain'].notnull().sum(),validate_sen_df_ca['sentence_domain'].notnull().sum(),unvalidate_sen_df_ca['sentence_domain'].notnull().sum())"
      ],
      "metadata": {
        "id": "flF-89SvJnHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dae8f04-4fd4-4cec-dd91-141cebe82640"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1877, 13) (1586, 13) (12901, 13)\n",
            "values of en: 102 1 1\n",
            "values of de: 5 32 3\n",
            "values of ca: 219 2 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def cleaned_data(other_df,validate_sen_df,unvalidate_sen_df,lan):\n",
        "#   other_df_cleaned = other_df.dropna(subset=['sentence_domain'], inplace=False)\n",
        "#   validate_sen_df_cleaned = validate_sen_df.dropna(subset=['sentence_domain'], inplace=False)\n",
        "#   unvalidate_sen_df_cleaned = unvalidate_sen_df.dropna(subset=['sentence_domain'], inplace=False)\n",
        "#   print(other_df_cleaned.shape,validate_sen_df_cleaned.shape,unvalidate_sen_df_cleaned.shape)\n",
        "#   result = pd.concat([other_df_cleaned,validate_sen_df_cleaned,unvalidate_sen_df_cleaned], axis=0)\n",
        "#   print(result.shape)\n",
        "#   file_path = \"/content/drive/MyDrive/neural dataset/{}/other_cleaned.tsv\".format(lan)\n",
        "#   result.to_csv(file_path, sep='\\t', index=False)\n",
        "#   return(result)\n",
        "\n",
        "# df_en = cleaned_data(other_df_en,validate_sen_df_en,unvalidate_sen_df_en,'en')\n",
        "# df_de = cleaned_data(other_df_de,validate_sen_df_de,unvalidate_sen_df_de,'de')\n",
        "# df_ca = pd.read_csv('/content/drive/MyDrive/neural dataset/ca/other_cleaned.tsv', sep='\\t')[:102]"
      ],
      "metadata": {
        "id": "K0PdoXwfBSdL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# def allclips(df,lan):\n",
        "#   # Source folder containing the MP3 files\n",
        "\n",
        "#   path = '/content/drive/MyDrive/neural dataset/{}/clips'.format(lan)\n",
        "#   source_folder = path\n",
        "\n",
        "#   # Destination folder where MP3 files will be moved\n",
        "#   destination_folder = '/content/drive/MyDrive/neural dataset/allclips'\n",
        "\n",
        "#   # Create destination folder if it doesn't exist\n",
        "#   os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "#   # Loop through each row in the DataFrame\n",
        "#   for index, row in df.iterrows():\n",
        "#       # Extract the MP3 file name from the 'path' column\n",
        "#       mp3_file = os.path.basename(row['path'])\n",
        "\n",
        "#       # Construct the full path of the MP3 file in the source folder\n",
        "#       source_path = os.path.join(source_folder, mp3_file)\n",
        "\n",
        "#       # Construct the full path of the MP3 file in the destination folder\n",
        "#       destination_path = os.path.join(destination_folder, mp3_file)\n",
        "\n",
        "#       # Check if the MP3 file exists in the source folder\n",
        "#       if os.path.exists(source_path):\n",
        "#           # Move the MP3 file from the source folder to the destination folder\n",
        "#           shutil.move(source_path, destination_path)\n",
        "#           print(f\"Moved {mp3_file} to {destination_folder}\")\n",
        "#       else:\n",
        "#           print(f\"MP3 file {mp3_file} not found in the source folder\")\n",
        "\n",
        "#   print(\"All MP3 files have been moved.\")\n",
        "\n",
        "\n",
        "# allclips(df_en,'en')\n",
        "# # allclips(df_de,'de')\n"
      ],
      "metadata": {
        "id": "bDzW-xxD7vxa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"other:\",other_df_en_cleaned.columns)\n",
        "# print(\"validate:\",validate_sen_df_en_cleaned.columns)\n",
        "# print(\"unvalidate:\",unvalidate_sen_df_en_cleaned.columns)\n",
        "# df_ca.shape"
      ],
      "metadata": {
        "id": "dciDYFhTCU_S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# time_steps = 16000  # Assuming 1 second audio clips with a sampling rate of 16 kHz\n",
        "# num_mfcc_features = 13  # Example value for the number of MFCC features\n"
      ],
      "metadata": {
        "id": "y3L0m1_l0nmA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_audio(file_path, sr=16000):\n",
        "    data,sr = lr.load(file_path)\n",
        "    return data\n",
        "\n",
        "validate_sen_df_en['audio'] = validate_sen_df_en['path'].apply(lambda x: load_audio(f'/content/drive/MyDrive/neural dataset/en/clips/{x}'))\n",
        "validate_sen_df_ca['audio'] = validate_sen_df_ca['path'].apply(lambda x: load_audio(f'/content/drive/MyDrive/neural dataset/ca/val_clips/{x}'))\n",
        "# df_total['audio'] = df_total['path'].apply(lambda x: load_audio(f'/content/drive/MyDrive/neural dataset/allclips/{x}'))\n",
        "\n",
        "# dev_df['audio'] = dev_df['path'].apply(lambda x: load_audio(f'/content/drive/MyDrive/neural dataset/te/clips/{x}'))\n",
        "# test_df['audio'] = test_df['path'].apply(lambda x: load_audio(f'/content/drive/MyDrive/neural dataset/te/clips/{x}'))"
      ],
      "metadata": {
        "id": "-77Rrnu91GaZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_sen_df_ca.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "vEM2Rw2rI3la",
        "outputId": "ca58645f-8c49-470b-bcef-ba79242a56b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           client_id  \\\n",
              "0  0bf9a3c9eebf8e427fa1d08800532c4bb279c13c113446...   \n",
              "\n",
              "                           path  \\\n",
              "0  common_voice_ca_39702834.mp3   \n",
              "\n",
              "                                         sentence_id  \\\n",
              "0  d159405abc07362ede5b393be7a63233f72fdc766a3186...   \n",
              "\n",
              "                                            sentence sentence_domain  \\\n",
              "0  La finalització de la guerra obrí un tens perí...             NaN   \n",
              "\n",
              "   up_votes  down_votes       age           gender accents variant locale  \\\n",
              "0         2           0  fourties  female_feminine     NaN     NaN     ca   \n",
              "\n",
              "   segment                                              audio  \n",
              "0      NaN  [-3.9815347e-12, -8.749569e-13, -4.1578212e-12...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7094ab52-f4e3-4495-827e-71b30aeea697\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>path</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentence_domain</th>\n",
              "      <th>up_votes</th>\n",
              "      <th>down_votes</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accents</th>\n",
              "      <th>variant</th>\n",
              "      <th>locale</th>\n",
              "      <th>segment</th>\n",
              "      <th>audio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0bf9a3c9eebf8e427fa1d08800532c4bb279c13c113446...</td>\n",
              "      <td>common_voice_ca_39702834.mp3</td>\n",
              "      <td>d159405abc07362ede5b393be7a63233f72fdc766a3186...</td>\n",
              "      <td>La finalització de la guerra obrí un tens perí...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>fourties</td>\n",
              "      <td>female_feminine</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ca</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[-3.9815347e-12, -8.749569e-13, -4.1578212e-12...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7094ab52-f4e3-4495-827e-71b30aeea697')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7094ab52-f4e3-4495-827e-71b30aeea697 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7094ab52-f4e3-4495-827e-71b30aeea697');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "validate_sen_df_ca",
              "summary": "{\n  \"name\": \"validate_sen_df_ca\",\n  \"rows\": 1586,\n  \"fields\": [\n    {\n      \"column\": \"client_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 59,\n        \"samples\": [\n          \"0bf9a3c9eebf8e427fa1d08800532c4bb279c13c113446c7507857ed53dbe058fae56bb0cf3db94e38ac53927e2165ca7e66cad3a46cae0afb21a5b8eed5b776\",\n          \"648a7a2a915bb43ddf94a74c2d0c3b3e23e0443cbe379f18d4c0ec9582b46ab8a52fe08189031603f1358a4c9d956aec3379d7ebaf6be259d746f33b84d92b70\",\n          \"2484ec5ade2d6f4d4f4018c366912fef0116608a55cc756d241646e2e18fbc8fc1cf53e04d9234e02e2054197686160cf9b647650ade74a1832a774c89752207\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1586,\n        \"samples\": [\n          \"common_voice_ca_39978668.mp3\",\n          \"common_voice_ca_39852414.mp3\",\n          \"common_voice_ca_39761018.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1584,\n        \"samples\": [\n          \"d875725fd0884d69e47deab4b68407c663ad7425d970db9fdc50c1d0c7b228b1\",\n          \"b051131e2de13090ff6bf6778ae691efc0e949f8c234e8719e62b8bd9d7f0ed2\",\n          \"d508eaaf9fe67820569ce9f92c4eeb3df9ba5e366497f8b4588a446c0ec24332\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1584,\n        \"samples\": [\n          \"Li van disparar per l\\u2019esquena quan intentava escapar-se dels policies.\",\n          \"A finals de novembre, replegar\\u00e0s la teua oliva sempre.\",\n          \"A la segona fase es jugaren vint-i-tres eliminat\\u00f2ries.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"food_service_retail\",\n          \"automotive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"up_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"down_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"fourties\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male_masculine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"valenci\\u00e0,Castell\\u00f3 de la Plana\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variant\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Valenci\\u00e0 septentrional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"locale\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ca\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"segment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # df_total = pd.concat([validate_sen_df_en,validate_sen_df_ca], axis=0)\n",
        "# # df_total.shape\n",
        "# validate_sen_df_en.to_csv('/content/drive/MyDrive/neural dataset/data_en.csv', index=False)\n",
        "# validate_sen_df_ca.to_csv('/content/drive/MyDrive/neural dataset/data_ca.csv', index=False)"
      ],
      "metadata": {
        "id": "rDSmxUPwCDo-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate_sen_df_en = pd.read_csv('/content/drive/MyDrive/neural dataset/data_en.csv')\n",
        "# validate_sen_df_ca = pd.read_csv('/content/drive/MyDrive/neural dataset/data_ca.csv')\n"
      ],
      "metadata": {
        "id": "_49EMOTrIKui"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_total = pd.concat([validate_sen_df_en,validate_sen_df_ca], axis=0)\n",
        "df_total.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "3NNYvWFUH-_R",
        "outputId": "c3b804e2-814b-4bae-f19b-57e69ec69be8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           client_id  \\\n",
              "0  01e8ea298cdecf26e273f5baac3915eb992c493f229686...   \n",
              "\n",
              "                           path  \\\n",
              "0  common_voice_en_39751075.mp3   \n",
              "\n",
              "                                         sentence_id  \\\n",
              "0  e5e7d4694b7160add018a08876327f254690c1ab4c39ea...   \n",
              "\n",
              "                                            sentence sentence_domain  \\\n",
              "0  Madin was a significant figure of post-war Bir...             NaN   \n",
              "\n",
              "   up_votes  down_votes  age gender                                 accents  \\\n",
              "0         2           0  NaN    NaN  United States English,New York English   \n",
              "\n",
              "  variant locale  segment                                              audio  \n",
              "0     NaN     en      NaN  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73297a8a-2f80-4555-9251-bbed562b61d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>path</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentence_domain</th>\n",
              "      <th>up_votes</th>\n",
              "      <th>down_votes</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accents</th>\n",
              "      <th>variant</th>\n",
              "      <th>locale</th>\n",
              "      <th>segment</th>\n",
              "      <th>audio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01e8ea298cdecf26e273f5baac3915eb992c493f229686...</td>\n",
              "      <td>common_voice_en_39751075.mp3</td>\n",
              "      <td>e5e7d4694b7160add018a08876327f254690c1ab4c39ea...</td>\n",
              "      <td>Madin was a significant figure of post-war Bir...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United States English,New York English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73297a8a-2f80-4555-9251-bbed562b61d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73297a8a-2f80-4555-9251-bbed562b61d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73297a8a-2f80-4555-9251-bbed562b61d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_total",
              "summary": "{\n  \"name\": \"df_total\",\n  \"rows\": 3463,\n  \"fields\": [\n    {\n      \"column\": \"client_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 435,\n        \"samples\": [\n          \"0debffd64018e6ec9b8706b996df4fdd7470774170f9d8da46600ad86d68f9e09a2f09d0dbfee4027ff7241c89ba1a3136cdfff40ad9c92f002c943a6f6e1a61\",\n          \"718fc490d46fcc55a2bae12a0dec7c3f9d6444a907d38c30712106497827e32ae89dec06b41532d2effbd72ed2944c4714e7e8daae50ddfeb7e6e10a1abc9e90\",\n          \"9dc051959870e443479ac04840758c8c10096804504e183c3849bc231fb7423fdad2419852f71281d8661f8862ac35b17d5e984ae990e3a897dc8ec9d77d34c6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3463,\n        \"samples\": [\n          \"common_voice_ca_39899611.mp3\",\n          \"common_voice_en_39747377.mp3\",\n          \"common_voice_ca_39907498.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3459,\n        \"samples\": [\n          \"a8825d5d458ec7355516f0293d23fa23323de4068b52789ed550e0ec5bfa82ce\",\n          \"e4112c2174dfaaa6c7a7a1556f699f9633c561675b6aaaca85a2f71897e2a259\",\n          \"d5cb8ef3d2c2d0d5b29c89fa1d216811aca63f129ed6af95f2867c91bebde5c9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3459,\n        \"samples\": [\n          \"The slug is caught in the sea off Samoa.\",\n          \"During this time, Konstantin's first campaign took place under the leadership of Suvorov.\",\n          \"De sobte el mon\\u00f2lit emet un senyal ac\\u00fastic eixordador.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"technology_robotics\",\n          \"automotive\",\n          \"food_service_retail\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"up_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 12,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          3,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"down_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"teens\",\n          \"twenties\",\n          \"fifties\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"transgender\",\n          \"male_masculine\",\n          \"female_feminine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 135,\n        \"samples\": [\n          \"European accent\",\n          \"England English, north yorkshire\",\n          \"Singaporean English\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variant\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Valenci\\u00e0 septentrional\",\n          \"Central\",\n          \"Valenci\\u00e0 meridional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"locale\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ca\",\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"segment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the two DataFrames are named other_df_en and another_df\n",
        "# And they both have a 'sentence_id' column\n",
        "\n",
        "# Merge the two DataFrames based on 'sentence_id'\n",
        "# merged_df = pd.merge(validate_sen_df_en,other_df_en, on='sentence_id', suffixes=('_en', '_another'))\n",
        "\n",
        "# # Now you can compare the columns or perform further analysis on the merged data\n",
        "# # print(merged_df.head())\n",
        "# merged_df.head()"
      ],
      "metadata": {
        "id": "1gV7mNdp8Ea3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the other DataFrame is named 'another_df' and it has 'sentence_id' and 'domain' columns\n",
        "# Mapping sentence_id to domain values in a dictionary\n",
        "# id_to_domain = dict(zip(validate_sen_df_en['sentence_id'], validate_sen_df_en['sentence_domain']))\n",
        "\n",
        "# first2pairs = {k: id_to_domain[k] for k in list(id_to_domain)[:2]}\n",
        "# print(first2pairs)\n",
        "# # Fill null values in 'sentence_domain' column with values from 'another_df'\n",
        "# other_df_en['sentence_domain'] = other_df_en['sentence_domain'].fillna(other_df_en['sentence_id'].map(id_to_domain))"
      ],
      "metadata": {
        "id": "MJ2jhPbrRUOq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import librosa as lr\n",
        "\n",
        "# def extract_features(audio, n_mfcc=13, hop_length=512, n_fft=2048):\n",
        "#     mfcc = lr.feature.mfcc(y=audio, sr=16000, n_mfcc=n_mfcc,\n",
        "#                            hop_length=hop_length, n_fft=n_fft)\n",
        "#     return mfcc.T  # Transpose to align time to rows\n",
        "\n",
        "# df_total['features'] = df_total['audio'].apply(extract_features)\n",
        "# # dev_df['features'] = dev_df['audio'].apply(extract_features)\n",
        "# # test_df['features'] = test_df['audio'].apply(extract_features)\n",
        "\n",
        "# # Print the shapes of the extracted features\n",
        "# print(df_total['features'][0].shape)  # Assuming you want to check the shape of the first sample\n",
        "import librosa as lr\n",
        "\n",
        "def extract_features(audio, n_mels=128, hop_length=512, n_fft=2048):\n",
        "    mel_spectrogram = lr.feature.melspectrogram(y=audio, sr=16000, n_mels=n_mels,\n",
        "                                                hop_length=hop_length, n_fft=n_fft)\n",
        "    return mel_spectrogram.T  # Transpose to align time to rows\n",
        "\n",
        "# Assuming df_total['audio'] contains the audio data\n",
        "df_total['features'] = df_total['audio'].apply(extract_features)\n",
        "\n",
        "# Print the shapes of the extracted features\n",
        "print(df_total['features'][0].shape)  # Assuming you want to check the shape of the first sample\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StxzsCKF7win",
        "outputId": "85630ea9-6b0c-4063-b792-f22f428483f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_lengths = []\n",
        "for features in df_total['features']:\n",
        "    features_lengths.append(features.shape[0])\n"
      ],
      "metadata": {
        "id": "oLtOCNgTosuB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate statistics\n",
        "mean_length = np.mean(features_lengths)\n",
        "median_length = np.median(features_lengths)\n",
        "percentile_90 = np.percentile(features_lengths, 90)\n",
        "percentile_95 = np.percentile(features_lengths, 95)\n",
        "\n",
        "print(f\"Mean mel-spectrogram length: {mean_length:.2f}\")\n",
        "print(f\"Median mel-spectrogram length: {median_length}\")\n",
        "print(f\"90th percentile mel-spectrogram length: {percentile_90}\")\n",
        "print(f\"95th percentile mel-spectrogram length: {percentile_95}\")\n",
        "\n",
        "# Plot a histogram\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(features_lengths, bins=50, edgecolor='black')\n",
        "plt.xlabel('Mel-spectrogram Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Mel-spectrogram Lengths')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "40Rmhs2Bo07u",
        "outputId": "a07c0e8c-8850-4928-c4ac-494cc882b268"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean mel-spectrogram length: 220.74\n",
            "Median mel-spectrogram length: 214.0\n",
            "90th percentile mel-spectrogram length: 311.8000000000002\n",
            "95th percentile mel-spectrogram length: 338.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming you have a maximum length for the features\n",
        "max_length = 256  # Replace with the desired maximum length\n",
        "\n",
        "# Define a padding function\n",
        "def pad_features(features, max_length):\n",
        "    padded_features = np.zeros((max_length, features.shape[1]))\n",
        "    if features.shape[0] > max_length:\n",
        "        padded_features = features[:max_length, :]\n",
        "    else:\n",
        "        padded_features[:features.shape[0], :] = features\n",
        "    return padded_features\n",
        "\n",
        "# Pad the features in the dataframes\n",
        "df_total['features'] = df_total['features'].apply(lambda x: pad_features(x, max_length))\n",
        "# dev_df['features'] = dev_df['features'].apply(lambda x: pad_features(x, max_length))\n",
        "# test_df['features'] = test_df['features'].apply(lambda x: pad_features(x, max_length))\n",
        "\n",
        "# Now you can convert the features to NumPy arrays\n",
        "X = np.array(df_total['features'].tolist())\n",
        "y_domain =(df_total['sentence_domain'])\n",
        "y_lan = (df_total['locale'])\n",
        "\n",
        "# X_dev = np.array(dev_df['features'].tolist())\n",
        "# y_dev = np.array(dev_df['sentence'])\n",
        "\n",
        "# X_test = np.array(test_df['features'].tolist())\n",
        "# y_test = np.array(test_df['sentence'])"
      ],
      "metadata": {
        "id": "UXsfMQ5WlYjO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Assuming df_total['locale'] and df_total['sentence_domain'] are the columns with string labels\n",
        "# Initialize label encoders\n",
        "label_encoder_lang = LabelEncoder()\n",
        "label_encoder_domain = LabelEncoder()\n",
        "\n",
        "# Fit label encoder and return encoded labels\n",
        "y_lan = label_encoder_lang.fit_transform(df_total['locale'].dropna())\n",
        "# y_domain = label_encoder_domain.fit_transform(df_total['sentence_domain'].dropna())\n",
        "# print(y_domain.shape)\n",
        "# Get the number of classes from the fitted label encoder\n",
        "num_language_classes = len(label_encoder_lang.classes_)\n",
        "# num_domain_classes = len(label_encoder_domain.classes_)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_lan_encoded = to_categorical(y_lan, num_classes=num_language_classes)\n",
        "# y_domain_encoded= 1\n",
        "\n",
        "# y_domain_encoded = to_categorical(y_domain, num_classes=num_domain_classes)\n",
        "y_lan_encoded.shape"
      ],
      "metadata": {
        "id": "fZFMdkHybAut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75eab63-9a36-415a-dae1-4fe4d6c54ea2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3463, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,y_lan_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "767MFxcVsKJ0",
        "outputId": "50369e74-9f33-4e8d-8f00-91b7802305a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3463, 256, 128), (3463, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_lan_train, y_lan_test = train_test_split(\n",
        "    X, y_lan_encoded, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Optionally, split the training set further to create a validation set (e.g., 80% of the remaining train for training, 20% for validation)\n",
        "X_train, X_val, y_lan_train, y_lan_val = train_test_split(\n",
        "    X_train, y_lan_train, test_size=0.2, random_state=42\n",
        ")\n",
        "# X_train, X_test, y_domain_train, y_domain_test, y_lan_train, y_lan_test = train_test_split(\n",
        "#     X, y_domain_encoded, y_lan_encoded, test_size=0.3, random_state=42\n",
        "# )\n",
        "\n",
        "# # Optionally, split the training set further to create a validation set (e.g., 80% of the remaining train for training, 20% for validation)\n",
        "# X_train, X_val, y_domain_train, y_domain_val, y_lan_train, y_lan_val = train_test_split(\n",
        "#     X_train, y_domain_train, y_lan_train, test_size=0.2, random_state=42\n",
        "# )\n",
        "\n",
        "# Check the shape of each set to ensure everything is correct\n",
        "# print(\"Training set:\", X_train.shape, y_domain_train.shape, y_lan_train.shape)\n",
        "# print(\"Validation set:\", X_val.shape, y_domain_val.shape, y_lan_val.shape)\n",
        "# print(\"Test set:\", X_test.shape, y_domain_test.shape, y_lan_test.shape)"
      ],
      "metadata": {
        "id": "-38tZ9ffTcFS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QTG9f_GkArda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)/ 255.0\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)/ 255.0\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)/255.0"
      ],
      "metadata": {
        "id": "ab5_KYcFnQN5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_domain_classes= 5\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfsVb2gm9DGv",
        "outputId": "73521309-f13a-492b-b1bd-275d19fe0c9a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1939, 256, 128, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model(input_shape, num_domain_classes, num_language_classes):\n",
        "    model = models.Sequential([\n",
        "        # Input layer\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        # First conv layer\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        # layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Second conv layer\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        # layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Third conv layer\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        # layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "\n",
        "        # Flatten the output of the conv layers to feed into the dense layer\n",
        "        layers.Flatten(),\n",
        "\n",
        "        # Dense layer for feature interpretation\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        # Separate output layers for domain and language classification\n",
        "        layers.Dense(num_language_classes, activation='softmax'),\n",
        "        # layers.Dense(num_domain_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Assuming you have already defined input_shape, num_domain_classes, and num_language_classes\n",
        "input_shape = X_train[0].shape  # Example: (MFCC_Time, MFCC_Features, 1) e.g., (32, 13, 1)\n",
        "print(input_shape)\n",
        "# Create the model\n",
        "model = create_cnn_model(input_shape, num_domain_classes, num_language_classes)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "8fUQtfCMtjC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bb937c-5576-41f3-c74c-dbf2164b0aa4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 128, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 128, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 128, 64, 32)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 64, 32)       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 64, 64)       18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 32, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16777472  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16870658 (64.36 MB)\n",
            "Trainable params: 16870658 (64.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "# history = model.fit(X_train, {'domain_output': y_domain_train, 'language_output': y_lan_train},\n",
        "#                     validation_data=(X_val, {'domain_output': y_domain_val, 'language_output': y_lan_val}),\n",
        "#                     epochs=20, batch_size=32)\n",
        "\n",
        "history = model.fit(X_train, y_lan_train,epochs=20,validation_data=(X_val,y_lan_val), batch_size=32)\n",
        "\n",
        "# history = model.fit(X_train, y_domain_train,epochs=20,validation_data=(X_val,y_domain_val), batch_size=32)"
      ],
      "metadata": {
        "id": "jv0jbv0LHZEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "# test_loss, test_accuracy = model.evaluate(X_test,y_domain_test)\n",
        "test_loss, test_accuracy = model.evaluate(X_test,y_lan_test)\n",
        "print('Test Accuracy:', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3-v6C2xHF-3",
        "outputId": "afbb06a2-0958-446c-cbfb-9ee5dafba438"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 24ms/step - loss: 0.7446 - accuracy: 0.8306\n",
            "Test Accuracy: 0.8306063413619995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rnn_model(input_shape, num_domain_classes, num_language_classes):\n",
        "    model = models.Sequential([\n",
        "        # Input layer\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        # LSTM layer\n",
        "        layers.LSTM(64, return_sequences=True),\n",
        "\n",
        "        # Dropout layer\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        # LSTM layer\n",
        "        layers.LSTM(64),\n",
        "\n",
        "        # Dropout layer\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        # Dense layer for feature interpretation\n",
        "        layers.Dense(256, activation='relu'),\n",
        "\n",
        "        # Output layer for language classification\n",
        "        layers.Dense(num_language_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape1=X_train.shape[1:-1]\n",
        "#  (X_train.shape[1],X_train.shape[2])\n",
        "model_rnn = create_rnn_model(input_shape1, num_domain_classes, num_language_classes)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI6vw6navXX2",
        "outputId": "d90d3cd1-67e8-486c-e429-9ecad3b8ebc9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 128, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 128, 64, 32)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 64, 32)       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 64, 64)       18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 32, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16777472  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16870658 (64.36 MB)\n",
            "Trainable params: 16870658 (64.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "# history = model.fit(X_train, {'domain_output': y_domain_train, 'language_output': y_lan_train},\n",
        "#                     validation_data=(X_val, {'domain_output': y_domain_val, 'language_output': y_lan_val}),\n",
        "#                     epochs=20, batch_size=32)\n",
        "\n",
        "history_rnn = model_rnn.fit(X_train, y_lan_train,epochs=20,validation_data=(X_val,y_lan_val), batch_size=32)\n",
        "\n",
        "# history = model.fit(X_train, y_domain_train,epochs=20,validation_data=(X_val,y_domain_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62guXEQnw2HW",
        "outputId": "db1b26de-f5b3-40e1-9763-b13b1714e3c0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "61/61 [==============================] - 8s 53ms/step - loss: 0.6916 - accuracy: 0.5281 - val_loss: 0.6872 - val_accuracy: 0.4866\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6885 - accuracy: 0.5090 - val_loss: 0.6786 - val_accuracy: 0.5567\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 2s 27ms/step - loss: 0.6829 - accuracy: 0.5111 - val_loss: 0.6756 - val_accuracy: 0.5216\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 2s 26ms/step - loss: 0.6959 - accuracy: 0.5049 - val_loss: 0.6864 - val_accuracy: 0.5505\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 0.6815 - accuracy: 0.5255 - val_loss: 0.6823 - val_accuracy: 0.5567\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 2s 27ms/step - loss: 0.6800 - accuracy: 0.4972 - val_loss: 0.6809 - val_accuracy: 0.5629\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 2s 26ms/step - loss: 0.6720 - accuracy: 0.5250 - val_loss: 0.6802 - val_accuracy: 0.4969\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 0.6751 - accuracy: 0.5132 - val_loss: 0.6841 - val_accuracy: 0.4866\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6912 - accuracy: 0.5250 - val_loss: 0.6821 - val_accuracy: 0.5567\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 2s 32ms/step - loss: 0.6874 - accuracy: 0.5193 - val_loss: 0.6832 - val_accuracy: 0.5649\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 2s 27ms/step - loss: 0.6841 - accuracy: 0.5152 - val_loss: 0.6559 - val_accuracy: 0.6103\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 2s 28ms/step - loss: 0.6680 - accuracy: 0.6070 - val_loss: 0.6156 - val_accuracy: 0.7052\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 2s 27ms/step - loss: 0.6517 - accuracy: 0.6462 - val_loss: 0.6085 - val_accuracy: 0.6866\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 0.6461 - accuracy: 0.6452 - val_loss: 0.5982 - val_accuracy: 0.7072\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 2s 28ms/step - loss: 0.6996 - accuracy: 0.5199 - val_loss: 0.6881 - val_accuracy: 0.5567\n",
            "Epoch 16/20\n",
            "61/61 [==============================] - 2s 28ms/step - loss: 0.6944 - accuracy: 0.5116 - val_loss: 0.6911 - val_accuracy: 0.5567\n",
            "Epoch 17/20\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6932 - accuracy: 0.5276 - val_loss: 0.6898 - val_accuracy: 0.5567\n",
            "Epoch 18/20\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.6932 - accuracy: 0.5101 - val_loss: 0.6911 - val_accuracy: 0.5567\n",
            "Epoch 19/20\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 0.6922 - accuracy: 0.5348 - val_loss: 0.6921 - val_accuracy: 0.5567\n",
            "Epoch 20/20\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 0.6955 - accuracy: 0.5054 - val_loss: 0.6894 - val_accuracy: 0.5567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "# test_loss, test_accuracy = model.evaluate(X_test,y_domain_test)\n",
        "test_loss, test_accuracy = model_rnn.evaluate(X_test,y_lan_test)\n",
        "print('Test Accuracy:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLVdXgRsxxy2",
        "outputId": "2ca0d922-3a91-4e43-9fae-6ac7c457ef6d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5736\n",
            "Test Accuracy: 0.5736284852027893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghrf2a3u3iAt",
        "outputId": "ab7fb721-785c-49a8-f83e-615e2a8accb0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/611.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_transformer_model(input_shape, num_domain_classes, num_language_classes):\n",
        "    # Encoder\n",
        "    encoder_inputs = layers.Input(shape=input_shape)\n",
        "    encoder_dense = layers.Flatten()(encoder_inputs)\n",
        "    encoder_dense = layers.Dense(128, activation='relu')(encoder_dense)\n",
        "    encoder_dense = layers.Dropout(0.5)(encoder_dense)\n",
        "    encoder_output = layers.Dense(128, activation='relu')(encoder_dense)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = layers.Input(shape=input_shape)\n",
        "    decoder_dense = layers.Flatten()(decoder_inputs)\n",
        "    decoder_dense = layers.Dense(128, activation='relu')(decoder_dense)\n",
        "    decoder_dense = layers.Dropout(0.5)(decoder_dense)\n",
        "    decoder_output = layers.Dense(128, activation='relu')(decoder_dense)\n",
        "\n",
        "    # Output layers\n",
        "    output = layers.Concatenate()([encoder_output, decoder_output])\n",
        "    output = layers.Dense(256, activation='relu')(output)\n",
        "    output = layers.Dropout(0.5)(output)\n",
        "    language_output = layers.Dense(num_language_classes, activation='softmax')(output)\n",
        "    # domain_output = layers.Dense(num_domain_classes, activation='softmax', name='domain_output')(output)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = models.Model(inputs=[encoder_inputs, decoder_inputs], outputs=language_output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = X_train.shape[1:]  # Input shape for the encoder\n",
        "\n",
        "print(input_shape)\n",
        "num_domain_classes = 10  # Number of domain classes\n",
        "num_language_classes = 2  # Number of language classes\n",
        "\n",
        "model_ts = create_transformer_model(input_shape, num_domain_classes, num_language_classes)\n",
        "model_ts.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMeA53nZ-yft",
        "outputId": "8842865d-ee2f-4495-9a8e-2b65de4ee066"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 128, 1)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)        [(None, 256, 128, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)        [(None, 256, 128, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)         (None, 32768)                0         ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 32768)                0         ['input_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 128)                  4194432   ['flatten_7[0][0]']           \n",
            "                                                                                                  \n",
            " dense_22 (Dense)            (None, 128)                  4194432   ['flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 128)                  0         ['dense_20[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 128)                  0         ['dense_22[0][0]']            \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 128)                  16512     ['dropout_13[0][0]']          \n",
            "                                                                                                  \n",
            " dense_23 (Dense)            (None, 128)                  16512     ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 256)                  0         ['dense_21[0][0]',            \n",
            " )                                                                   'dense_23[0][0]']            \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 256)                  65792     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 256)                  0         ['dense_24[0][0]']            \n",
            "                                                                                                  \n",
            " dense_25 (Dense)            (None, 2)                    514       ['dropout_15[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8488194 (32.38 MB)\n",
            "Trainable params: 8488194 (32.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_ts = model_ts.fit([X_train, X_train], y_lan_train, validation_data=([X_val, X_val], y_lan_val), epochs=20, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpv7OyJI2-Qq",
        "outputId": "e78761d0-690f-4ffa-931e-3c420f42dcde"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "61/61 [==============================] - 12s 160ms/step - loss: 0.6764 - accuracy: 0.6065 - val_loss: 0.5921 - val_accuracy: 0.7010\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 8s 124ms/step - loss: 0.5656 - accuracy: 0.7550 - val_loss: 0.6522 - val_accuracy: 0.6722\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 7s 122ms/step - loss: 0.4195 - accuracy: 0.8221 - val_loss: 0.7020 - val_accuracy: 0.6825\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.2662 - accuracy: 0.8912 - val_loss: 0.9683 - val_accuracy: 0.6907\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 7s 114ms/step - loss: 0.1727 - accuracy: 0.9469 - val_loss: 0.8847 - val_accuracy: 0.7485\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.1268 - accuracy: 0.9634 - val_loss: 1.0470 - val_accuracy: 0.7361\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 7s 116ms/step - loss: 0.1167 - accuracy: 0.9680 - val_loss: 1.2902 - val_accuracy: 0.7258\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 10s 170ms/step - loss: 0.0713 - accuracy: 0.9742 - val_loss: 1.4660 - val_accuracy: 0.7381\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 7s 112ms/step - loss: 0.0861 - accuracy: 0.9789 - val_loss: 1.3188 - val_accuracy: 0.7567\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 10s 167ms/step - loss: 0.0673 - accuracy: 0.9778 - val_loss: 1.6537 - val_accuracy: 0.7320\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.0451 - accuracy: 0.9866 - val_loss: 1.5542 - val_accuracy: 0.7464\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 1.6188 - val_accuracy: 0.7505\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 7s 120ms/step - loss: 0.0410 - accuracy: 0.9876 - val_loss: 1.8121 - val_accuracy: 0.7340\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 1.8461 - val_accuracy: 0.7299\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 14s 233ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 1.8754 - val_accuracy: 0.7608\n",
            "Epoch 16/20\n",
            "61/61 [==============================] - 11s 180ms/step - loss: 0.0225 - accuracy: 0.9969 - val_loss: 1.9764 - val_accuracy: 0.7485\n",
            "Epoch 17/20\n",
            "61/61 [==============================] - 10s 157ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 2.3339 - val_accuracy: 0.7361\n",
            "Epoch 18/20\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 2.2607 - val_accuracy: 0.7443\n",
            "Epoch 19/20\n",
            "61/61 [==============================] - 7s 115ms/step - loss: 0.0150 - accuracy: 0.9938 - val_loss: 2.3896 - val_accuracy: 0.7485\n",
            "Epoch 20/20\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.0357 - accuracy: 0.9954 - val_loss: 2.2908 - val_accuracy: 0.7670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have separate test data (X_test, y_lan_test)\n",
        "test_loss, test_accuracy = model_ts.evaluate([X_test, X_test], y_lan_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bg2T9tN6LIA",
        "outputId": "865de214-a584-474f-8293-3c303a59f2e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 21ms/step - loss: 2.6655 - accuracy: 0.7440\n",
            "Test Loss: 2.6655\n",
            "Test Accuracy: 0.7440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "niFJZ7SbVWqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8GOEwyQ1VWmk"
      }
    }
  ]
}